{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ANT pc\\AppData\\Roaming\\Python\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing PDF: pdfs1\\3M_2015_10K.pdf\n",
      "Converted 158 pages to Base64 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing pages:  31%|███       | 49/158 [01:18<02:30,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APIError: 500 Internal error encountered.. Retrying in 5 seconds...\n",
      "APIError: 500 Internal error encountered.. Retrying in 5 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing pages:  33%|███▎      | 52/158 [01:24<02:36,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APIError: 500 Internal error encountered.. Retrying in 5 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing pages:  75%|███████▌  | 119/158 [03:23<01:01,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APIError: 500 Internal error encountered.. Retrying in 5 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing pages: 100%|██████████| 158/158 [04:19<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcriptions saved to output\\3M_2015_10K_transcription.txt\n",
      "Processing PDF: pdfs1\\3M_2016_10K.pdf\n",
      "Converted 233 pages to Base64 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing pages:  15%|█▍        | 34/233 [00:58<03:58,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APIError: 500 Internal error encountered.. Retrying in 5 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing pages:  62%|██████▏   | 144/233 [03:58<01:40,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APIError: 500 Internal error encountered.. Retrying in 5 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing pages: 100%|██████████| 233/233 [05:40<00:00,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcriptions saved to output\\3M_2016_10K_transcription.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fitz  # PyMuPDF\n",
    "import io\n",
    "import base64\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import random\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the Gemini API key\n",
    "gemini_api_key = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "if not gemini_api_key:\n",
    "    raise EnvironmentError(\"GEMINI_API_KEY is not set. Please add it to your .env file.\")\n",
    "\n",
    "# Configure the Gemini API\n",
    "genai.configure(api_key=gemini_api_key)\n",
    "model = genai.GenerativeModel(\"gemini-1.5-flash\")  # Initialize the Gemini model\n",
    "\n",
    "def pdf_to_base64_images(pdf_path):\n",
    "    \"\"\"\n",
    "    Converts a PDF into Base64-encoded images for all pages.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        pdf_document = fitz.open(pdf_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error opening PDF {pdf_path}: {e}\")\n",
    "        return []\n",
    "\n",
    "    def process_page(page):\n",
    "        try:\n",
    "            pix = page.get_pixmap()\n",
    "            img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "            buffered = io.BytesIO()\n",
    "            img.save(buffered, format=\"PNG\")\n",
    "            return base64.b64encode(buffered.getvalue()).decode()\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing page {page.number + 1}: {e}\")\n",
    "            return None\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        base64_images = list(executor.map(process_page, [pdf_document[i] for i in range(len(pdf_document))]))\n",
    "\n",
    "    pdf_document.close()\n",
    "    return [img for img in base64_images if img is not None]\n",
    "\n",
    "def process_summary_from_image(base64_str, max_retries=3, retry_delay=5):\n",
    "    \"\"\"\n",
    "    Uses Gemini to transcribe text from a Base64-encoded image.\n",
    "    \"\"\"\n",
    "    text_prompt =  \"\"\"\n",
    "    You will be given an image containing text. Your task is to accurately transcribe all the text from this image. \n",
    "    Pay special attention to names, tables and numbers.\n",
    "\n",
    "    Follow these steps to complete the task:\n",
    "    1. Carefully examine the entire image.\n",
    "    2. Transcribe all visible text exactly as it appears in the image.\n",
    "    3. If any text is unclear or illegible, do not attempt to guess or fill in information. Instead, indicate unclear text with [unclear] in your transcription.\n",
    "    4. Pay particular attention to visual elements such as tables, charts, and diagrams. Ensure these are transcribed accurately and in a clear, organized manner.\n",
    "    5. If the order of information in the image is not clear, think step by step about the logical flow of the content. Arrange the transcribed information in a relevant and coherent order.\n",
    "    6. Do not add any information that is not present in the image.\n",
    "    7. Do not include any preamble or explanation about the transcription process in your response.\n",
    "    8. For Visual Elements:\n",
    "        a. For tables: Transcribe headers, rows, and columns in a markdown table format, ensuring proper alignment and structure.\n",
    "        b. For charts or diagrams: Provide a detailed description of the type (e.g., bar chart, flowchart), layout, and any labeled data points.\n",
    "        Example Markdown Table:\n",
    "        | Column 1 Header | Column 2 Header | Column 3 Header |\n",
    "        |---------------- |-----------------|-----------------|\n",
    "        | Row 1, Cell 1   | Row 1, Cell 2   | Row 1, Cell 3   |\n",
    "        | Row 2, Cell 1   | Row 2, Cell 2   | Row 2, Cell 3   |\n",
    "        | Row 3, Cell 1   | Row 3, Cell 2   | Row 3, Cell 3   |\n",
    "    9. Your response should only contain the transcribed content from the image, organized in a logical manner if necessary.\n",
    "    10. If you encounter any issues or if the image is not clear enough to transcribe, explain the problem instead of providing a transcription.\n",
    "    \"\"\"\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = model.generate_content([\n",
    "                text_prompt,  # Include a text prompt as required by the API\n",
    "                {\n",
    "                    \"mime_type\": \"image/png\",\n",
    "                    \"data\": base64.b64decode(base64_str)\n",
    "                }\n",
    "            ])\n",
    "            time.sleep(random.uniform(0.5, 1.5))  # Introduce a slight delay to avoid rate limits\n",
    "            return response.text\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"APIError: {e}. Retrying in {retry_delay} seconds...\")\n",
    "            time.sleep(retry_delay)\n",
    "\n",
    "    print(\"Max retries reached. Unable to process the image.\")\n",
    "    return None\n",
    "\n",
    "def split_image(image):\n",
    "    \"\"\"\n",
    "    Splits a large image into smaller parts to avoid API issues.\n",
    "    \"\"\"\n",
    "    width, height = image.size\n",
    "    max_height = 1024  # Set a reasonable height limit\n",
    "    parts = []\n",
    "\n",
    "    for top in range(0, height, max_height):\n",
    "        box = (0, top, width, min(top + max_height, height))\n",
    "        part = image.crop(box)\n",
    "        buffered = io.BytesIO()\n",
    "        part.save(buffered, format=\"PNG\")\n",
    "        parts.append(base64.b64encode(buffered.getvalue()).decode())\n",
    "\n",
    "    return parts\n",
    "\n",
    "def process_pdf_to_text(pdf_path):\n",
    "    \"\"\"\n",
    "    Complete pipeline for processing a PDF file:\n",
    "    1. Convert PDF pages to images.\n",
    "    2. Split images if needed.\n",
    "    3. Transcribe images to text using Gemini (parallel processing).\n",
    "    \"\"\"\n",
    "    print(f\"Processing PDF: {pdf_path}\")\n",
    "\n",
    "    base64_images = pdf_to_base64_images(pdf_path)\n",
    "    print(f\"Converted {len(base64_images)} pages to Base64 images.\")\n",
    "\n",
    "    if not base64_images:\n",
    "        print(f\"No images to process for PDF {pdf_path}. Skipping transcription.\")\n",
    "        return []\n",
    "\n",
    "    transcriptions = []\n",
    "\n",
    "    def transcribe(index, base64_image):\n",
    "        try:\n",
    "            decoded_image = Image.open(io.BytesIO(base64.b64decode(base64_image)))\n",
    "            image_parts = split_image(decoded_image) if decoded_image.size[1] > 1024 else [base64_image]\n",
    "\n",
    "            page_transcription = []\n",
    "            for part in image_parts:\n",
    "                transcription = process_summary_from_image(part)\n",
    "                if transcription:\n",
    "                    page_transcription.append(transcription)\n",
    "\n",
    "            return index, \"\\n\".join(page_transcription)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing page {index + 1}: {e}\")\n",
    "            return index, None\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=5) as executor:\n",
    "        futures = {executor.submit(transcribe, i, img): i for i, img in enumerate(base64_images)}\n",
    "\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Transcribing pages\"):\n",
    "            index, transcription = future.result()\n",
    "            if transcription:\n",
    "                transcriptions.append((index, transcription))\n",
    "\n",
    "    transcriptions.sort()\n",
    "    return [t[1] for t in transcriptions]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_directory = \"pdfs1\"  \n",
    "    output_directory = \"output\"  \n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    pdf_files = [f for f in os.listdir(pdf_directory) if f.endswith(\".pdf\")]\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        pdf_path = os.path.join(pdf_directory, pdf_file)\n",
    "        transcriptions = process_pdf_to_text(pdf_path)\n",
    "\n",
    "        if not transcriptions:\n",
    "            print(f\"No transcriptions generated for {pdf_file}. Skipping saving.\")\n",
    "            continue\n",
    "\n",
    "        output_file = os.path.join(output_directory, f\"{os.path.splitext(pdf_file)[0]}_transcription.txt\")\n",
    "        with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            for i, transcription in enumerate(transcriptions, start=1):\n",
    "                f.write(f\"### Page {i}\\n{transcription}\\n\\n\")\n",
    "\n",
    "        print(f\"Transcriptions saved to {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
